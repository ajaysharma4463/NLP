{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this video we will discuss vizulization part\n",
    "# how to diplay spacy\n",
    "# by importing library from spacy called displacy\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"aad2fed14ded4837978997a7f6a81311-0\" class=\"displacy\" width=\"1250\" height=\"387.0\" direction=\"ltr\" style=\"max-width: none; height: 387.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\"> </tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">U.K</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">million</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aad2fed14ded4837978997a7f6a81311-0-0\" stroke-width=\"2px\" d=\"M70,252.0 C70,152.0 235.0,152.0 235.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aad2fed14ded4837978997a7f6a81311-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,254.0 L62,242.0 78,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aad2fed14ded4837978997a7f6a81311-0-1\" stroke-width=\"2px\" d=\"M170,252.0 C170,202.0 230.0,202.0 230.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aad2fed14ded4837978997a7f6a81311-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,254.0 L162,242.0 178,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aad2fed14ded4837978997a7f6a81311-0-2\" stroke-width=\"2px\" d=\"M370,252.0 C370,202.0 430.0,202.0 430.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aad2fed14ded4837978997a7f6a81311-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,254.0 L362,242.0 378,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aad2fed14ded4837978997a7f6a81311-0-3\" stroke-width=\"2px\" d=\"M270,252.0 C270,152.0 435.0,152.0 435.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aad2fed14ded4837978997a7f6a81311-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M435.0,254.0 L443.0,242.0 427.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aad2fed14ded4837978997a7f6a81311-0-4\" stroke-width=\"2px\" d=\"M570,252.0 C570,102.0 840.0,102.0 840.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aad2fed14ded4837978997a7f6a81311-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570,254.0 L562,242.0 578,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aad2fed14ded4837978997a7f6a81311-0-5\" stroke-width=\"2px\" d=\"M570,252.0 C570,202.0 630.0,202.0 630.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aad2fed14ded4837978997a7f6a81311-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M630.0,254.0 L638.0,242.0 622.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aad2fed14ded4837978997a7f6a81311-0-6\" stroke-width=\"2px\" d=\"M770,252.0 C770,202.0 830.0,202.0 830.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aad2fed14ded4837978997a7f6a81311-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,254.0 L762,242.0 778,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aad2fed14ded4837978997a7f6a81311-0-7\" stroke-width=\"2px\" d=\"M470,252.0 C470,52.0 845.0,52.0 845.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aad2fed14ded4837978997a7f6a81311-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M845.0,254.0 L853.0,242.0 837.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aad2fed14ded4837978997a7f6a81311-0-8\" stroke-width=\"2px\" d=\"M470,252.0 C470,2.0 950.0,2.0 950.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aad2fed14ded4837978997a7f6a81311-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,254.0 L958.0,242.0 942.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aad2fed14ded4837978997a7f6a81311-0-9\" stroke-width=\"2px\" d=\"M1070,252.0 C1070,202.0 1130.0,202.0 1130.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aad2fed14ded4837978997a7f6a81311-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1070,254.0 L1062,242.0 1078,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aad2fed14ded4837978997a7f6a81311-0-10\" stroke-width=\"2px\" d=\"M970,252.0 C970,152.0 1135.0,152.0 1135.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aad2fed14ded4837978997a7f6a81311-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1135.0,254.0 L1143.0,242.0 1127.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc=nlp(\"Apple is going to build a  U.K factory for 6 million\")\n",
    "\n",
    "displacy.render(doc,style=\"dep\",jupyter=True,options={'distance':100})\n",
    "# we use render function diplay the dependeny of sentense\n",
    "# arrows are syntactic dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">over the last quater \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " store lot of inforamtion on their clount with a cost of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc=nlp(\"over the last quater Apple store lot of inforamtion on their clount with a cost of $6 billion \")\n",
    "displacy.render(doc,style=\"ent\",jupyter=True)\n",
    "# it highlited Apple with entity ORG(organizayion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style has two parameter ent,dep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whenever we search a word like example 'boat' so result could be \"boats\" or \"boating\" or etc\n",
    "# it is a crude method   for categorical  words, it is essentially important to choff off letters from then \n",
    "#end untel the stem is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #spacy doest not provide stemmer process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steamming can be acheive by porter algorithm developed by martin porter in 1980\n",
    "#the algorithm has five steps\n",
    "1- in this suffix will be removed  if they match the condition\n",
    "sses--ss\n",
    "ies---i\n",
    "ss----ss\n",
    "s-----(blank)\n",
    "ational--ate\n",
    "eed--ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowball is a  name of steamming  language devloped by martin porter\n",
    "# this alhorith is callled \"english stemmer\" or \"porter2 stemmer\" . it provide much accurate result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W now create a object of PorterStemmer\n",
    "porter=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['run','runs','runner','easily','fairly','chess']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "runs\n",
      "runner\n",
      "easily\n",
      "fairly\n",
      "chess\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run======>run\n",
      "runs======>run\n",
      "runner======>runner\n",
      "easily======>easili\n",
      "fairly======>fairli\n",
      "chess======>chess\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word +\"======>\"+ porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'language'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5dce7927a9f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# now we will use snowball\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnowball\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msnow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'language'"
     ]
    }
   ],
   "source": [
    "# now we will use snowball\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snow=SnowballStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow=SnowballStemmer(language=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run======>run\n",
      "runs======>run\n",
      "runner======>runner\n",
      "easily======>easili\n",
      "fairly======>fair\n",
      "chess======>chess\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word +\"======>\"+ snow.stem(word)) # check faieli to fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whenver words meaning is similar then output will be same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lemmalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it just not reduce words  but also see the whle word\n",
    "# i think it covert out sentence to full vocabulary sentene\n",
    "# it can perform in spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=nlp(\"i am a runner running in a race  becasue i love to fun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i \t PRON \t 5097672513440128799 \t i\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "  \t SPACE \t 8532415787641010193 \t  \n",
      "becasue \t NOUN \t 477967224519361033 \t becasue\n",
      "i \t PRON \t 5097672513440128799 \t i\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t ADP \t 3791531372978436496 \t to\n",
      "fun \t NOUN \t 2579443659188327298 \t fun\n"
     ]
    }
   ],
   "source": [
    "for word in doc1:\n",
    "    print(word.text,'\\t',word.pos_,'\\t',word.lemma,'\\t',word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number are hash value  ehich point the lemma  ,check out 'run' words using same hash location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemma(text):\n",
    "    \n",
    "    for token in text:\n",
    "        \n",
    "        print('{token.text:{12}},{token.pos:{12}},{token.pos_:{12}},{token.lemma:{12}},{token.lemma_:{12}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{token.text:{12}},{token.pos:{12}},{token.pos_:{12}},{token.lemma:{12}},{token.lemma_:{12}}\n",
      "{token.text:{12}},{token.pos:{12}},{token.pos_:{12}},{token.lemma:{12}},{token.lemma_:{12}}\n",
      "{token.text:{12}},{token.pos:{12}},{token.pos_:{12}},{token.lemma:{12}},{token.lemma_:{12}}\n",
      "{token.text:{12}},{token.pos:{12}},{token.pos_:{12}},{token.lemma:{12}},{token.lemma_:{12}}\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"new run runner test\")\n",
    "show_lemma(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new         ,          84,ADJ         ,4753564829687343602,new         \n",
      "run         ,          92,NOUN        ,12767647472892411841,run         \n",
      "runner      ,          92,NOUN        ,12640964157389618806,runner      \n",
      "test        ,          92,NOUN        ,1618900948208871284,test        \n"
     ]
    }
   ],
   "source": [
    "def show_lemma(text):\n",
    "    \n",
    "    for token in text:\n",
    "        \n",
    "        print(f'{token.text:{12}},{token.pos:{12}},{token.pos_:{12}},{token.lemma:{12}},{token.lemma_:{12}}')\n",
    "        \n",
    "        \n",
    "doc=nlp(\"new run runner test\")\n",
    "show_lemma(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in our sentence  we have  multiple stop words which is nothing for NLP processing ,but it can hurt your \n",
    "#nLP processing so get rid of them as soon as possible\n",
    "# spacy holds a built -in list of some 305 english stop words\n",
    "# stop words do not give important information so get rid of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'as', 'between', 'make', 'move', 'than', 'nine', 'being', 'seemed', 'thereupon', 'behind', 'is', 'wherever', 'am', 'he', 'elsewhere', 'she', 'thence', 'side', 'others', 'anything', 'indeed', 'become', 'ever', 'namely', 'very', 'in', 'myself', 'never', 'see', 'somehow', 'wherein', 'together', 'last', 'get', '’d', 'across', 'front', 'their', 'among', 'perhaps', 'nothing', 'now', 'please', 'former', 'ca', 'either', 'one', 'forty', 'a', 'her', 'so', 'might', 'own', 'although', 'eleven', 'five', 'what', 'sixty', 'about', 'whole', 'therefore', '‘re', 'thereby', 'yourself', 'whereas', 'our', '‘ve', 'us', 'of', 'whereupon', 'top', 'him', 'becoming', 'other', 'thereafter', 'did', 'because', 'few', 'could', 'thus', 'next', 'an', '‘ll', 'beforehand', 'most', 'therein', 'too', '‘s', 'keep', 'three', 'someone', 'while', '’s', 'n’t', 'many', 'themselves', 'afterwards', 'herein', 'onto', 'anyone', 'amount', 'thru', 'hundred', 'already', 'within', 'to', 'each', 'anywhere', 'how', '’m', 'fifty', 'they', '’ll', 'part', 'at', 'everyone', 'fifteen', 'call', 'who', 'quite', 'almost', 'rather', 'no', 'show', 'such', 'further', 'doing', 'less', 'beyond', 'empty', 'it', 'go', 'was', 'more', 'toward', 'done', 'since', 'we', 'per', 'well', 'first', 'serious', 'around', 'whereby', 'hence', 'none', 'using', 'the', 'really', 'whence', 'every', 'on', 'them', 'when', 'yours', 'his', '‘m', 'here', 'me', 'twenty', 'via', 'hereafter', 'whether', 'say', 'else', 'put', 'been', 'moreover', 'formerly', 'below', 'used', 'whereafter', 'various', 'whither', 'nobody', 'and', 'until', 'however', 'except', 'besides', 'sometime', 'for', \"'ll\", 'amongst', 'nor', \"'m\", 'two', 'nevertheless', 'through', \"'ve\", 'mostly', 'also', 'anyhow', 'ourselves', '‘d', 'or', 'made', 'due', 'noone', 'all', 'again', 'will', 'after', \"'re\", 'name', 'something', 'ours', 'over', 'upon', 'four', 'mine', 'seems', 'those', 'eight', 'must', 'whenever', 'any', 'up', 'twelve', 'otherwise', 'himself', 'much', 'where', 'hers', 'not', 'would', 'give', 'throughout', 'that', 'without', 'may', 'both', 'were', 'latterly', 'beside', 'into', 'whatever', 'you', 'becomes', 'before', \"'s\", 'should', 'hereupon', 'latter', 'regarding', 'nowhere', 'became', 'seem', 'yourselves', 'everywhere', 'under', 'unless', 'whom', 'once', 'along', 'cannot', 'down', 'often', 'out', 'some', 'my', 'which', 'even', 'bottom', 'yet', 'least', 'somewhere', 'just', 'do', 'take', 'with', 'during', 'from', 'there', 'only', '’ve', 'have', 'does', 'be', 'whoever', 'neither', 'by', 'i', 'herself', 'six', 'sometimes', 'several', 'another', 'has', 'same', \"'d\", 'these', 'itself', 'n‘t', 'enough', 're', 'whose', '’re', 'against', 'why', 'can', 'its', 'meanwhile', 'full', 'anyway', 'hereby', 'back', 'ten', \"n't\", 'are', 'towards', 'above', 'but', 'alone', 'then', 'off', 'everything', 'if', 'this', 'though', 'always', 'third', 'your', 'still', 'had', 'seeming'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts has been increae and it is 326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can check wheather some word is stop word or not\n",
    "nlp.vocab[\"mystery\"].is_stop    # it is not stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[\"is\"].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x21395bc1228>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[\"is\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab[\"mystery\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can add our stop word like 'btw' by the way \n",
    "# most of the client use btw for sortcur=t but we can add in our stop word\n",
    "nlp.Defaults.stop_words.add(\"btw\")\n",
    "nlp.vocab[\"btw\"].is_stop=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[\"btw\"].is_stop   # becsue we just add it into stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  it will automatically added to our stop word container\n",
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can remove stop words from containner and tell nlp to use it as a impormation as a nrrew test come\n",
    "nlp.Defaults.stop_words.remove(\"fifty\")\n",
    "nlp.vocab[\"fifty\"].is_stop=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[\"fifty\"].is_stop   # so it is removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phrase matching and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can match our phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher  # caplital letter is impoetant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher=Matcher(nlp.vocab)   # created a matcher object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solarpower\n",
    "pattern1=[{'LOWER':'solarpower'}]\n",
    "# solar-power\n",
    "pattern2=[{'LOWER':'solar'},{'IS_PUNCT':True},{'LOWER':'power'}]\n",
    "# solar power\n",
    "pattern3=[{'LOWER':'solar'},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('solarpower',None,pattern1,pattern2,pattern3)\n",
    "#None=Call back parmeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3=nlp(\"solarpower is important SOLARPOWER industury,solar-power , solar power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5703546853475899243, 0, 1),\n",
       " (5703546853475899243, 3, 4),\n",
       " (5703546853475899243, 6, 9),\n",
       " (5703546853475899243, 10, 12)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher(doc3)  # it doesnt matter wheather it is upper letter or small letter\n",
    "# string id match 5703546853475899243\n",
    "#0, 1 start token location without adding last position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let use lower in small letter\n",
    "# dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solarpower\n",
    "pattern1=[{'lower':'solarpower'}]\n",
    "# solar-power\n",
    "pattern2=[{'lower':'solar'},{'IS_PUNCT':True},{'lower':'power'}]\n",
    "# solar power\n",
    "pattern3=[{'lower':'solar'},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('solarpower',None,pattern1,pattern2,pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3=nlp(\"solarpower is important SOLARPOWER industury,solar-power , solar power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5703546853475899243, 0, 1),\n",
       " (5703546853475899243, 3, 4),\n",
       " (5703546853475899243, 6, 9),\n",
       " (5703546853475899243, 10, 12)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can remove our matcher\n",
    "matcher.remove('solarpower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple punctuation in phrase word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solarpower\n",
    "pattern1=[{'lower':'solarpower'}]\n",
    "# solar-power\n",
    "pattern2=[{'lower':'solar'},{'IS_PUNCT':True ,'OP':'*'},{'lower':'power'}]\n",
    "# solar power\n",
    "pattern3=[{'lower':'solar'},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'OP':'*'}  multiple punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('solarpower',None,pattern1,pattern2,pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3=nlp(\"solarpower is important SOLARPOWER industury,solar--power , solar power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5703546853475899243, 0, 1),\n",
       " (5703546853475899243, 3, 4),\n",
       " (5703546853475899243, 6, 9),\n",
       " (5703546853475899243, 10, 12)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher(doc3)  ##{'OP':'*'} it consist two punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what if we want to search from file\n",
    "# we need to import file and search our words\n",
    "# PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase=PhraseMatcher(nlp.vocab)\n",
    "#normal syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C\\filelocation') as file:\n",
    "    doc3=nlp(file.read())\n",
    " # file has been added to doc3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now add your phrase\n",
    "phrase_list=['voodpp ecommm','supply chain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_matter=nlp(phrase_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('EconMatcher',None,*phrase_matter)\n",
    "# measn we added out matches into matchers\n",
    "# now we need to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found=matcher(doc3) # our doc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interview question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 impot file\n",
    "with open(\"../file anme\") as f:\n",
    "    doc=nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 length of token\n",
    "len(docfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many sentences\n",
    "doc_sentence=[sent for sent in doc.sents]\n",
    "doc_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print second sentence \n",
    "print(doc_sentence[1].text)  \n",
    "# 1 is index value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
